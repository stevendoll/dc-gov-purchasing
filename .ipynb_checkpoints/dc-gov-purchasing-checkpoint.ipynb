{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DC Government Purchasing\n",
    "Analysis of government purchase orders 2004-2015\n",
    "\n",
    "My interest was sparked by an article Homeless shelter plan could be profitable for Bowser’s backers https://www.washingtonpost.com/local/dc-politics/homeless-shelter-plan-could-be-profitable-for-bowsers-backers/2016/03/16/cbab0e76-eadc-11e5-b0fd-073d5930a7b7_story.html\n",
    "D.C. Mayor Muriel E. Bowser has pitched her plan to create family homeless shelters in almost every ward of the city as an equitable way for the community to share the burden of caring for the neediest residents.\n",
    "\n",
    "But records show that most of the private properties proposed as shelter sites are owned or at least partly controlled by major donors to the mayor. And experts have calculated that the city leases­ would increase the assessed value of those properties by as much as 10 times for that small group of landowners and developers.\n",
    "\n",
    "How much taxpayer money would be paid to a handful of well-connected private landowners, developers and their agents is expected to be a focus of a hearing Thursday before the D.C. Council.\n",
    "\n",
    "http://www.bayesimpact.org/stories/?name=the-mob-the-money-and-the-mayhem\n",
    "How Network Analysis Can Help Identify Money Laundering Schemes\n",
    "Written by Jonathon Morgan, Platform Architect at Ushahidi and Founder of CrisisNET \n",
    "Using Eliot’s tip and a public database of registered UK companies, we investigated whether a network analysis approach could identify potential smoking guns — sham companies, shady business connections, or at least organizations with the capacity for offshore money laundering.\n",
    "## Questions of interest\n",
    "Is it possible to identify transactions in a large dataset that may warrant further scrutiny?\n",
    "Which commodities and purchase sizes are most attractive for fraud or sleeze?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy: 1.10.4\n",
      "scipy: 0.17.0\n",
      "matplotlib: 1.5.1\n",
      "statsmodels: 0.6.1\n",
      "pandas: 0.17.1\n",
      "seaborn: 0.7.0\n",
      "sklearn: 0.17\n",
      "nltk: 3.1\n"
     ]
    }
   ],
   "source": [
    "# The %... is an iPython thing, and is not part of the Python language.\n",
    "# In this case we're just telling the plotting library to draw things on\n",
    "# the notebook, instead of on a separate window.\n",
    "%matplotlib inline \n",
    "#this line above prepares IPython notebook for working with matplotlib\n",
    "\n",
    "# See all the \"as ...\" contructs? They're just aliasing the package names.\n",
    "# That way we can call methods like plt.plot() instead of matplotlib.pyplot.plot().\n",
    "\n",
    "import numpy as np # imports a fast numerical programming library\n",
    "import scipy as sp #imports stats functions, amongst other things\n",
    "import matplotlib as mpl # this actually imports matplotlib\n",
    "import matplotlib.cm as cm #allows us easy access to colormaps\n",
    "import matplotlib.pyplot as plt #sets up plotting under plt\n",
    "import pandas as pd #lets us handle data as dataframes\n",
    "import seaborn as sns #sets up styles and gives us more plotting options\n",
    "\n",
    "import statsmodels\n",
    "import sklearn\n",
    "import nltk\n",
    "\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "#sets up pandas table display\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "print(\"numpy:\", np.__version__)\n",
    "print(\"scipy:\", sp.__version__)\n",
    "print(\"matplotlib:\", mpl.__version__)\n",
    "print(\"statsmodels:\", statsmodels.__version__)\n",
    "print(\"pandas:\", pd.__version__)\n",
    "print(\"seaborn:\", sns.__version__)\n",
    "print(\"sklearn:\", sklearn.__version__)\n",
    "print(\"nltk:\", nltk.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "The data is available at http://data.octo.dc.gov/ from 2004-2015 through csv files and excel. I unzipped the cvs files and converted the excel files to csv. The 2013 excel file was in the xlsx format, but converted easily.\n",
    "\n",
    "On inspection, the files and headers are structured in 3 distinct ways. \n",
    "\n",
    "The 2010 cvs would not import properly. On further inspection there was an item with quotes inside quotes, which caused the columns to not break properly. Line 7119:\n",
    "\"PENCILS, MARKING (INCLUDING MECHANICAL TYPES AND REFILLS): \"GREASE\" OR \"CHINA\" TYPES, ETC. 70\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded\n"
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "    \n",
    "    list_ = []\n",
    "    \n",
    "    for file_ in [\"data/Purchase_order_FY14.csv\", \"data/Purchase_order_FY15.csv\"]:\n",
    "        df = pd.read_csv(file_, header=0, names=['agency', 'commodity', 'supplier', 'order_date','po', 'amount'])\n",
    "        \n",
    "        df = df[df['po'].notnull()]\n",
    "\n",
    "        # data cleaning and type casting\n",
    "        df['agency'] = df.agency.astype(str).str.lower()\n",
    "        df['commodity'] = df.commodity.astype(str).str.lower()\n",
    "        df['supplier'] = df.supplier.astype(str).str.lower()\n",
    "        df['amount'] = df.amount.map(lambda x: x.replace(',', '')).astype(float)/1000\n",
    "        df['order_date'] = pd.to_datetime(df['order_date'])\n",
    "\n",
    "        list_.append(df)\n",
    "    \n",
    "    #PO Number\tAgency\tCommodity\tVendor Name\tOrdered DAte\tPO amount\n",
    "    for file_ in [\"data/Purchase_order_FY12.csv\", \"data/Purchase_order_FY13.csv\"]:\n",
    "        df = pd.read_csv(file_, header=3, names=['po', 'agency', 'commodity', 'supplier', 'order_date', 'amount'])\n",
    "        df = df[df['po'].notnull()]\n",
    "\n",
    "        # data cleaning and type casting\n",
    "        df['agency'] = df.agency.astype(str).str.lower()\n",
    "        df['commodity'] = df.commodity.astype(str).str.lower()\n",
    "        df['supplier'] = df.supplier.astype(str).str.lower()\n",
    "        df['amount'] = df.amount.map(lambda x: x.replace(',', '')).astype(float)/1000\n",
    "        df['order_date'] = pd.to_datetime(df['order_date'])\n",
    "\n",
    "        list_.append(df)\n",
    "    \n",
    "    # PO_NUMBER,AGENCY_NAME,NIGP_DESCRIPTION,PO_TOTAL_AMOUNT,ORDER_DATE,SUPPLIER,SUPPLIER_FULL_ADDRESS,SUPPLIER_CITY,SUPPLIER_STATE\n",
    "    # \"pass_2004_CSV.csv\", \"pass_2008_CSV.csv\", \"pass_2009_CSV.csv\", \"pass_2010_CSV.csv\", \n",
    "    files = [\"data/pass_2004_CSV.csv\", \"data/pass_2008_CSV.csv\", \"data/pass_2009_CSV.csv\", \"data/pass_2010_CSV.csv\", \"data/pass_2011_CSV.csv\"]\n",
    "    \n",
    "    for file_ in files:\n",
    "    \n",
    "        df = pd.read_csv(file_, skiprows=1, names=['po', 'agency', 'commodity', 'amount', 'order_date', 'supplier', 'supplier_address', 'supplier_city', 'supplier_state'])\n",
    "\n",
    "        df = df[df['po'].notnull()]\n",
    "\n",
    "        # data cleaning and type casting\n",
    "        df['agency'] = df.agency.astype(str).str.lower()\n",
    "        df['commodity'] = df.commodity.astype(str).str.lower()\n",
    "        df['supplier'] = df.supplier.astype(str).str.lower()\n",
    "        df['amount'] = df.amount.map(lambda x: x.replace(',', '')).map(lambda x: x.replace('$', '')).astype(float)/1000\n",
    "        df['order_date'] = pd.to_datetime(df['order_date'])\n",
    "\n",
    "        list_.append(df)\n",
    "        \n",
    "    df_result = pd.concat(list_)\n",
    "        \n",
    "    df_result = df_result[df_result['amount'] > 0]\n",
    "        \n",
    "    print(\"Data loaded\")\n",
    "\n",
    "    return df_result\n",
    "\n",
    "df = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
